{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf29bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 16:28:23.321268: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 16:28:23.321534: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-02 16:28:23.357659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-02 16:28:24.201903: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-02 16:28:24.202251: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from deepface import DeepFace\n",
    "\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.datasets import make_classification\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from qiskit import QuantumCircuit, Aer, transpile\n",
    "# #from qiskit.providers.aer import AerSimulator\n",
    "# from qiskit_machine_learning.neural_networks import TwoLayerQNN\n",
    "# from qiskit_machine_learning.algorithms import NeuralNetworkClassifier\n",
    "# from qiskit.utils import QuantumInstance\n",
    "# from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "# #from qiskit.algorithms.optimizers import COBYLA\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# only deep face ile face boundary çıkarma from folder Dataset/train\n",
    "import cv2\n",
    "def extract_faces_from_folder(folder_path, target_size=(64, 64)):\n",
    "    X = []\n",
    "    y = []\n",
    "    label_map = {} \n",
    "    current_label = 0\n",
    "\n",
    "    for subdir in os.listdir(folder_path):\n",
    "        subdir_path = os.path.join(folder_path, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            if subdir not in label_map:\n",
    "                label_map[subdir] = current_label\n",
    "                current_label += 1\n",
    "            label = label_map[subdir]\n",
    "\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, filename)\n",
    "                try:\n",
    "                    # Use DeepFace to detect and extract the face\n",
    "                    face_img = DeepFace.represent(file_path,  enforce_detection=True, model_name=\"Facenet512\", detector_backend='mtcnn')\n",
    "                    for face in face_img:\n",
    "                        print(face.get(\"facial_area\"))\n",
    "                        if face_img is not None:\n",
    "                            X.append(face.get(\"embedding\"))  \n",
    "                            y.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def  MinMaxScaler():\n",
    "    pass\n",
    "\n",
    "N_SAMPLES = 1800       \n",
    "N_FEATURES_INITIAL = 512 \n",
    "N_CLASSES = 8         \n",
    "N_QUBITS = 4           \n",
    "SHOTS = 1024           \n",
    "EPOCHS = 30            \n",
    "LEARNING_RATE = 0.01   \n",
    "BATCH_SIZE = 16        \n",
    "# face boundary çıkarma ve\n",
    "# DeepFace kullanarak yüzleri çıkar\n",
    "X_train, y_train = extract_faces_from_folder('Dataset/train')\n",
    "X_test, y_test = extract_faces_from_folder('Dataset/test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_faces_train.npy', X_train)\n",
    "np.save('y_labels_train.npy', y_train)\n",
    "np.save('X_faces_test.npy', X_test)\n",
    "np.save('y_labels_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908fd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_faces_train.npy')\n",
    "y_train = np.load('y_labels_train.npy')\n",
    "\n",
    "X_test = np.load('X_faces_test.npy')\n",
    "y_test = np.load('y_labels_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f3164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Başlangıç Veri Boyutu (X): (297, 512)\n",
      "Etiket Boyutu (y): (297,)\n",
      "Extracted 297 faces with 512 features each.\n",
      "Labels shape: (297,)\n",
      "PCA sonrası Veri Boyutu (X_pca): (297, 6)\n",
      "1782\n",
      "Ölçeklendirilmiş Veri Boyutu (X_scaled): (297, 6)\n",
      "Eğitim verisi boyutu: (207, 6)\n",
      "Test verisi boyutu: (90, 6)\n",
      "\n",
      "Tam Kuantum Devresi (Feature Map + Ansatz):\n",
      "\n",
      "QNN Giriş Parametreleri: [ParameterVectorElement(x[0]), ParameterVectorElement(x[1]), ParameterVectorElement(x[2]), ParameterVectorElement(x[3])]\n",
      "QNN Ağırlık Parametreleri: [ParameterVectorElement(θ[0]), ParameterVectorElement(θ[1]), ParameterVectorElement(θ[2]), ParameterVectorElement(θ[3]), ParameterVectorElement(θ[4]), ParameterVectorElement(θ[5]), ParameterVectorElement(θ[6]), ParameterVectorElement(θ[7]), ParameterVectorElement(θ[8]), ParameterVectorElement(θ[9]), ParameterVectorElement(θ[10]), ParameterVectorElement(θ[11])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "if X_train.shape[0] != y_train.shape[0]:\n",
    "    raise ValueError(\"Number of samples in X and y do not match!\")\n",
    "\n",
    "if X_test.shape[0] != y_test.shape[0]:\n",
    "    raise ValueError(\"Number of samples in X_test and y_test do not match!\")\n",
    "if X_train.shape[1] != N_FEATURES_INITIAL:\n",
    "    raise ValueError(f\"Expected {N_FEATURES_INITIAL} features, but got {X_train.shape[1]}\")\n",
    "\n",
    "# --- Özellik Ölçekleme ---\n",
    "pca = PCA(n_components=6)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(f\"PCA sonrası Veri Boyutu (X_pca): {X_pca.shape}\")\n",
    "print(X_pca.size)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "X_scaled = scaler.fit_transform(X_pca)\n",
    "print(f\"Ölçeklendirilmiş Veri Boyutu (X_scaled): {X_scaled.shape}\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "X_scaled = scaler.fit_transform(X_pca)\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch ile çalışmak için verileri Tensor formatına dönüştürüyoruz.\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# DataLoader, verileri batch'ler halinde modele beslememizi sağlar.\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Eğitim verisi boyutu: {X_train.shape}\")\n",
    "print(f\"Test verisi boyutu: {X_test.shape}\")\n",
    "\n",
    "from qiskit.circuit import ParameterVector\n",
    "\n",
    "# --- Adım 3: Kuantum Veri Kodlama (Feature Map) ---\n",
    "feature_params = ParameterVector('x', length=N_QUBITS)\n",
    "\n",
    "# ŞİMDİ, bu parametreleri kullanacağımız boş devreyi oluşturuyoruz.\n",
    "feature_map = QuantumCircuit(N_QUBITS, name=\"FeatureMap\")\n",
    "for i in range(N_QUBITS):\n",
    "    feature_map.ry(feature_params[i], i)\n",
    "\n",
    "# feature_map.draw('mpl', style='iqx') # Bu satır hala çalışır.\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "# --- Adım 4: Parametreli Kuantum Devresi (Ansatz) ---\n",
    "ansatz = RealAmplitudes(N_QUBITS, reps=2, entanglement='linear')\n",
    "ansatz.draw('mpl', style='iqx')\n",
    "\n",
    "\n",
    "# Kuantum Devresini Oluşturma\n",
    "qc = QuantumCircuit(N_QUBITS)\n",
    "qc.compose(feature_map, inplace=True)\n",
    "qc.compose(ansatz, inplace=True)\n",
    "print(\"\\nTam Kuantum Devresi (Feature Map + Ansatz):\")\n",
    "qc.draw('mpl', style='iqx')\n",
    "\n",
    "\n",
    "# --- QNN'i Qiskit'te Tanımlama ---\n",
    "from qiskit.primitives import StatevectorEstimator\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "observable_strings = ['I'*i + 'Z' + 'I'*(N_QUBITS-1-i) for i in range(N_QUBITS)]\n",
    "\n",
    "observables = [SparsePauliOp(s) for s in observable_strings]\n",
    "\n",
    "qnn = EstimatorQNN(\n",
    "    circuit=qc,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    "    observables=observables,  \n",
    "    estimator=StatevectorEstimator() \n",
    ")\n",
    "print(f\"\\nQNN Giriş Parametreleri: {qnn.input_params}\")\n",
    "print(f\"QNN Ağırlık Parametreleri: {qnn.weight_params}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
